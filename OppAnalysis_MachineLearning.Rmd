---
title: 'Gasbarro Capstone Project: Opportunities Analysis - Machine Learning'
output:
  pdf_document:
    toc: yes
  word_document:
    toc: yes
date: "August 9, 2019"
params:
  symbol: Not Applicable
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, LIBRARIES, echo=FALSE, warning=FALSE, error=FALSE, message=FALSE}
## IMPORTING THE SPREADSHEET

library(readxl)
library(tidyverse)
library(dplyr)
library(readxl)
library(stringr)
library(lubridate)
library(ggplot2)
library(xts)
library(scales)
```

```{r, LOAD_SPREADSHEETS, echo=FALSE, warning=FALSE, error=FALSE, message=FALSE}
## IMPORTING THE SPREADSHEET
opps_revised_2019 <- readRDS("opps_revised_2019.rds")
#summary(opps_revised_2019)
# Select only the opportunities that were WON
opps_won_2019 <- opps_revised_2019 %>% filter(stage_simple=='WON',expected_revenue_usd<50000000,expected_revenue_usd>0)

```

\newpage
# Introduction
[Back to Contents](#toc)

In the previous assignments (see: OppAnalysis_DataStory_FINAL), we had explored various aspects of the dataset for sale opportunities. While some trends appeared to emerge (e.g. the number of WON opportunities seemed to decline over 3 years), there were outstanding factors (e.g. a company merger might have impacted sales data) and no strong correlation among the variables and observations.  

As we embark on the linear modeling and machine learning phase of this project, we'd like to answer 2 key questions.  

1. AGE. We had not used AGE in our previous data exploration and analysis. Age is the number of days between the start of the sale activity and the date when the opportunity is closed (WON, LOST). 
Is there a relationship or correlation between
1A. Age and how many deals are WON or LOST?
1B. Age and Expected Revenue?  

2. LM and PREDICTION. 
2A. If we know AGE (number of days it takes to close a WON opportunity), can we predict how much money the WON Expected Revenue might be?
2B. If we know Industry and Age, can we predict how much money the WON Expected Revenue might be?  

The formula for prediction is based on the INPUT and the LM generated based on the variables in the dataset. The formula may be expressed as follows:
*INPUT -> FUNCTION (LM Regression) -> OUTPUT*
*INPUT -> EXPECTED REVENUE ~ AGE -> OUTPUT*


\newpage
# Opportunities: Correlation 
[Back to Contents](#toc)  
Now let's work with the real sales data in Opportunities.

Is there a strong correlation between the AGE and the EXPECTED REVENUE among WON? The correlation is `r cor(opps_won_2019$age, opps_won_2019$expected_revenue_usd)`, which doesn't seem that significant.  

What does the relationship look like when we plot using geom_point? It appears there is some correlation, as shown by the graph below.  
```{r, Opps_ggplot_age_exprev, echo=FALSE, warning=FALSE, error=FALSE, message=FALSE}
ggplot(data = opps_won_2019, aes(x = age, y = expected_revenue_usd)) +
  geom_point() +
  scale_y_log10()
```

\newpage
# Opportunities: Linear Model
[Back to Contents](#toc)  

We'll now create a linear model of the Expected Revenue as a function of Age. The Summar is printed below the code.  

```{r, Opps_LinearModel, echo=TRUE, warning=FALSE, error=FALSE, message=FALSE}
ageMod <- lm(expected_revenue_usd ~ age, data=opps_won_2019)
summary(ageMod)

#Residual Standard Error (Like Standard Deviation)
#k=length(ageMod$coefficients)-1 #Subtract one to ignore intercept
#SSE=sum(ageMod$residuals**2)
#n=length(ageMod$residuals)
#sqrt(SSE/(n-(1+k))) #Residual Standard Error

```

## Coefficients
The **Estimated Intercept** is the mean Expected Revenue for an opportunity when we consider the number of Days for the opportunity to close successfully (WON). In our current model, the Estimated Intercept is `r coef(ageMod)["(Intercept)"]` USD.  

The **Estimated Slope** is the impact that Age has on the Expected Revenue for an opportunity. For every 1 day it takes an opportunity to close, the Expected Revenue increases by `r coef(ageMod)["age"]` USD.  

The **Standard Error** measures the average amount that the model's estimates (based on the coefficient) differs from the actual average of the variables. In this model, the standard errors for the intercept is nearly 1014 USD, while the standard error for the slope (Age) is 5 USD. Ideally, these numbers should be very low, meaning the difference between the model's estimates and the actual variables is low and fairly accurate. However, given the large volume of observations, and the wide range of values for Estimated Revenue, the size of these Standard Error values might not be too concerning.  

The **t-value** is a measure of how many standard deviations the model's estimate is far away from 0. Ideally, these numbers should be far away from zero - it would mean we could reject the null hypothesis and declare a relationship between Age and Expected Revenue. The current model shows t-values well above zero, especially in regard to Age. This indicates a relationship could exist between Age and Expected Amount.  

## Residual Standard Error
The Residual standard error is the average amount that the response will deviate from the regression line. In our current model, the RSE is `r sigma(ageMod)` USD. Even for the range of possible values in Expected Revenue, this seems very high.  
If we wanted to calculate the percentage error (how much a prediction might be off) we would divide the Residual standard error (RSE) by the mean (Intercept).
% Error = `r (sigma(ageMod)/coef(ageMod)["(Intercept)"])*100` %  

## R-squared
R-squared tells us how well the model fits the actual data, measured in a value between 0 and 1. R-squared values closer to 1 indicate the model fits the data very well, while lower values indicate the fit is weak or non-existent. In our current model, the R-squared value is `r summary(ageMod)$r.squared`, which is very low, suggesting the model does not fit the data very strongly.  

## F-Statistic
The F-Statistic indicates whether there is a relationship between the predictor (Age) and the the response (Expected Revenue). Based on the R documentation and other coursework, F-statistic values should be greater than. The F-statistic in our model is `r summary(ageMod)$fstatistic`, which indicates there is a relationship between the predictor and response, especially given the large size of the dataset.  

## P-Value
Last but definitely not least... The **P-value (and Pr(>|t|))** is the probability that we'll observe any value equal to or larger than the t-value. Another way of saying it (that makes sense to me) is: the probability that we would observe a relationship between Age and Expected Revenue by chance. According to courses at Datacamp and Khan Academy, a p-value of 5% (0.05) or less indicates "significance" - that a relationship/trend/etc. is significant and cannot be explained by the null hypothesis.  

In our model, the p-value is quite small: 2.2. x -10 ^ -16 or 0.00000000000000022. This is very close to zero, falling well below the threshhold of 0.05 that is traditionally used in statistics.  

Note: R documentation indicates that the presence of 3 asterisks (***) means the p-value has significance.  

\newpage
# Opportunities: Simple Prediction
[Back to Contents](#toc)  

We'll prepare a data frame with a new Age value, then run a prediction using the linear model ageMod generated in the previous exercise.  

```{r, Opps_Predict, echo=TRUE, warning=FALSE, error=FALSE, message=FALSE}
new_age <- data.frame(age=100)
new_age_predict <- as.numeric(predict(ageMod, newdata=new_age))
```
Based on the formula in the linear model, if the Age is 100 days, then the Expected Revenue for a WON deal is expected to be ```r new_age_predict```.  

What if we predict the Expected Revenue for ALL the observations? How far would the predictions be from the actual Expected Revenue amounts that were recorded?
```{r, Opps_Predict_All, echo=TRUE, warning=FALSE, error=FALSE, message=FALSE}
opps_won_2019$predicted_revenue_usd <- predict(ageMod)

ggplot(opps_won_2019, aes(x = predicted_revenue_usd, y = expected_revenue_usd)) + 
  geom_point() +
  geom_abline(color = "blue")

```

The graph shows a lot of variance in the lower left corner, but as the line moves to the right (and there are fewer observations), there appear to be some success in the predictions. Overall, when the model is applied to the actual values, it appears to fit poorly.  

\newpage
# Opportunities: Conclusions So Far
[Back to Contents](#toc)  

Some of our statistics in the current ageMod model suggest 
* there is a relationship between Age and Expected Revenue
* the relationship cannot be disprov en by the null hypothesis

However, the R-squared value is very low, and the plot of predictions above (based on the model) above suggests the model might not be a good fit with the actual data in our dataset.  
\newpage
# Opportunities: Multiple Regression
[Back to Contents](#toc)  

We'll generate a new linear model using multiple regression, adding Industry Simple as a factor to the original formula.  
*Original: INPUT -> EXPECTED REVENUE ~ AGE -> OUTPUT*
*Modified: INPUT -> EXPECTED REVENUE ~ AGE + INDUSTRY -> OUTPUT*

```{r, Opps_LM_AgeIndustry, echo=TRUE, warning=FALSE, error=FALSE, message=FALSE}

opps_won_factor <- opps_won_2019
opps_won_factor$industry_simple <- as.factor(opps_won_factor$industry_simple)
str(opps_won_factor)

ageIndustryMod <- lm(expected_revenue_usd ~ age + industry_simple, data=opps_won_factor)
summary(ageIndustryMod)
ageIndustryMod_Intercept <- coef(ageIndustryMod)["(Intercept)"]
ageIndustryMod_Slope <- coef(ageIndustryMod)["age"]
```

Most of the statistics, while different from the previous model, appear in alignment with the previous statistics.  

The statistics which stand out as most striking are:  
* Coefficients:
** Utilities has a P-value close to zero and is identified by the model as being significant
** Transportation has a very high P-value and does not appear to have any significance
** Everything Else and Engineering appear to have significant P-values, though not as significant as the Utilities P-value
* The R-Square values have increased slightly from the previous model, confirming that there was room for improvement, and that adding more variables through multiple regression may yield better models.

## Mystery: Where did Distribution go?
The industry value Distribution did not appear in our model, even though it is present in the dataset. When we remove Everything Else or Transportation, it still doesn't appear. Why is lm() removing Distribution observations?  

It appears that LM is using Distribution as the base against which the other coefficients are being compared (Everything Else, Engineering, Utilities, Etc.)  

Can we change this, so the base is Everything Else? Yes, we'll use relevel.  

```{r, Opps_LM_AgeIndustry_Factor, echo=TRUE, warning=FALSE, error=FALSE, message=FALSE}

opps_won_factor$industry_simple <- relevel(opps_won_factor$industry_simple, ref="Everything Else")

ageIndustryMod <- lm(expected_revenue_usd ~ age + industry_simple, data=opps_won_factor,na.action=na.exclude)
summary(ageIndustryMod)
ageIndustryMod_Intercept <- coef(ageIndustryMod)["(Intercept)"]
ageIndustryMod_Slope <- coef(ageIndustryMod)["age"]

```
The new model shows numbers to the previous model for Industries.
* Neither Engineering nor Transportation has significant p-values.
* Distribution's coefficients are better
* Utilities still has the most significant p-value of all the industries in this model.
* The R-squared value remains at nearly 4%, which is still better than the simple linear model, and suggests we should try more variables in multiple and/or logical regression.  

What if we run the prediction on the factored dataset, using the new model we generated by industry? After applying the model using predict(), we use ggplot to contrast the Predicted Revenue values against the actual Expected Revenue.The graphs below illustrate the narrative we've been following.  
1. The first graph below shows the contrast between the Predicted Revenue (X-axis) and the actual Expected Revenue (Y-Axis). Across all industries, there doesn't seem a very strong model for prediction.  
2. The second graph shows the ggplot graph, but focused on a single industry, Utilities. This is the factor that had the strongest p-value and coefficients in our model. While still not perfect, it is considerably better than the previous predicted graph.  
3. The third graph shows the Age vs. Expected Revenue. The slope of this graph is nearly the same as the previous graph, which makes sense.  
4. The fourth graph shows the Age vs. Predicted Revenue, which shows what the graph of a well-fitted model would look like.

```{r, Opps_LM_AgeIndustry_Predict, echo=TRUE, warning=FALSE, error=FALSE, message=FALSE}

opps_won_factor$predicted_revenue_usd <- predict(ageIndustryMod,na.action = na.omit)

ggplot(opps_won_factor, aes(x = predicted_revenue_usd, y = expected_revenue_usd)) + 
  geom_point() +
  geom_abline(color = "blue")

ggplot(data = subset(opps_won_factor,industry_simple %in% c("Utilities")), aes(x = predicted_revenue_usd, y = expected_revenue_usd)) + 
  geom_point() +
  geom_abline(color = "blue")

ggplot(data = subset(opps_won_factor,industry_simple %in% c("Utilities")), aes(x = age, y = expected_revenue_usd, col=industry_simple)) +
  geom_point() +
  geom_smooth(method="lm", color="blue")

ggplot(data = subset(opps_won_factor,industry_simple %in% c("Utilities")), aes(x = age, y = predicted_revenue_usd, col=industry_simple)) +
  geom_point() +
  geom_smooth(method="lm", color="blue")

```


\newpage
# Conclusion: Next Steps
[Back to Contents](#toc)  

We created a simple linear model for Expected Revenue predicted by Age. This model seemed too simplistic. It is based solely on a single variable, Age. Other variables might impact the price in combination with Age, and offer a better model for making predictions.  


We then modified it to include a factor variable, Industry Simple, and reset the factor levels in the data frame, to ensure the base reference would be Everything Else (a conglomeration of all other industries), against which the coefficients for theother  factored Industries would be calculated.  

The initial results appear to show
* There IS a relationship between the variables Age, Industry, and Expected Revenue
* The fit between the actual data for all Industries, and the statistics in the model is weak, reducing its effectiveness in potentially predicting Expected Revenue.  
* However, Utilities stood out with significant p-value and strong coefficients. The graph showed that it had the strongest predictions against actual values (even if it still isn't perfect).  

This suggests that adding additional variables in some combination, or re-scoping and combining other variables (applying log function against numericals like Expected Revenue or factors like Stage and Currency) might produce models that are stronger, and can be used reliably to identify patterns, trends, and possible predictions for future behavior.  


```{r, SaveOurWork, echo=FALSE, warning=FALSE, error=FALSE, message=FALSE}
saveRDS(opps_revised_2019,file="opps_revised_2019.rds")
saveRDS(opps_won_2019,file="opps_won_2019.rds")
```
